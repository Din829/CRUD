# Prompt: 本项目未来测试与开发的指南与经验总结

## I. 核心项目理解与背景:
*   **项目:** LangGraph 数据库交互应用。
*   **架构:** LangGraph 应用层 (业务逻辑, LLM 调用) + Flask 后端 API 层 (直接数据库交互: `/get_schema`, `/execute_query`, `/insert_record`, `/update_record`, `/delete_record`, `/execute_batch_operations`)。
*   **测试重点:** 主要针对 Flask API 端点进行单元/集成测试，使用 `pytest`，测试数据源自 CSV 文件，并通过 fixture 重置数据库状态。
*   **沟通:** 默认使用中文。遵循用户提供的 `custom_instructions` (最小化改动、需求澄清、结构化解决方案、JSDoc 注释等)。

## II. API 测试关键经验与最佳实践 (尤其针对批量操作):

### A. 编写测试前:
1.  **深入理解 API 实现:**
    *   **行动:** 仔细阅读 `app.py` (或相关后端文件) 中目标 API 端点的代码。
    *   **原因:** 理解其确切的请求结构、响应格式 (成功与错误情况，特定字段如 `affected_data`、`operation_index`、`success` 标志、`last_insert_id`)、数据校验、依赖处理 (例如 `depends_on_index`, `return_affected`)、SQL 生成及事务逻辑。*切勿仅凭端点名称或通常预期来假设其行为。*
    *   **示例:** 我们在 `/execute_batch_operations` 的测试过程中发现，最初对响应字段的假设 (例如，每个操作是否包含通用 `status` 字段，或 `return_affected` 数据如何提供) 是通过仔细检查 `app.py` 代码才得以修正的。

2.  **理解数据 Fixture 和测试数据:**
    *   **行动:** 清楚了解 fixture (如 `db_setup_for_batch_tests`) 如何准备数据库状态。熟悉 CSV 文件 (`users.csv`, `prompts.csv` 等) 的内容和结构，包括潜在的 BOM 字符或空行问题。
    *   **原因:** 这对于预测结果和编写准确的断言至关重要，特别是对于那些对现有数据敏感的操作 (例如唯一约束冲突、`WHERE` 子句匹配、自增 ID 起始值)。

3.  **确保 Mock 与实际返回值的统一性 (新增关键经验):**
    *   **行动:** 在为外部依赖（如 API 客户端、LLM 服务）编写 Mock 时，务必通过检查实际服务行为（例如，通过主应用运行日志、API 文档或直接调用服务）来确认其真实的返回结构和类型。
    *   **原因:** Mock 的返回值（或 `side_effect`）必须与实际组件的行为完全一致。如果 Mock 的假设与实际情况不符（例如，Mock 假设返回字典，实际返回字符串），将导致集成测试通过但主应用在相同逻辑点失败，或者反之。
    *   **示例:** 在查询/分析流程的集成测试中，我们最初 Mock `llm_query_service.classify_query_analysis_intent` 返回一个包含意图的字典，但主应用日志显示它实际只返回一个意图字符串。这导致了主应用中的 `AttributeError`。修正 Mock 以匹配实际行为是解决问题的关键。
    *   **教训:** **主应用日志是验证LLM服务或其他外部服务实际输出格式的宝贵工具，尤其是在集成测试的Mock与主应用行为出现偏差时。**

### B. 设计测试用例与编写断言时:
1.  **系统性处理批量操作的复杂性:**
    *   **依赖关系:** 测试各种依赖类型：insert 依赖 insert，update 依赖 insert，以及由前序操作返回的多行结果影响后续操作的场景。验证占位符替换 (`{{previous_result[N].column}}`) 逻辑，确保 `N` 正确对应 `depends_on_index`。
    *   **操作展开:** 如果一个操作依赖于前一步骤返回的多行结果 (例如，一个 `update` 操作通过 `return_affected` 返回了多个行)，确保 API 能够正确地将该依赖操作扩展为多个子操作。对此进行显式测试。
    *   **事务完整性:** 严格测试回滚行为。如果批处理中的某个操作失败 (例如由于唯一约束、外键约束或数据类型不匹配)，验证该批处理中所有先前成功但未提交的操作是否都已回滚，且没有部分数据被持久化。
    *   **错误报告:** 确保批量操作的 API 错误响应能清晰指明:
        *   失败操作的 `operation_index`。
        *   具体的错误代码/类型 (例如 `IntegrityError.DuplicateEntry`, `ValueError` 表示不支持的操作符)。
        *   相关详情 (例如冲突值、表名、键名、具体的错误消息)。
        *   合适的 HTTP 状态码 (例如 409 对应重复条目，500 对应意外的服务器错误，400 对应错误的输入)。

2.  **编写动态且健壮的断言:**
    *   **避免硬编码行数:** 对于 `affected_rows` 或匹配 `WHERE` 子句的记录数，*不要*基于对测试数据的静态假设来硬编码数字，因为数据集可能会变化。
    *   **行动:** 在测试中的 API 调用之前，如果精确计数对于所测逻辑很重要，请使用与计划的 API 操作*相同的条件*查询数据库，以获取当前 fixture 状态下的*实际预期计数*。在断言中使用此动态计数值。
    *   **示例:** `test_batch_where_clause_operators` 最初因其 `affected_rows` 检查中断言 `WHERE id > 3` 匹配的行数多于硬编码的 '3' 而失败。通过预先查询计数解决了该问题。
    *   **数据库状态验证:** 操作执行后，查询数据库以确认*实际*状态符合预期 (例如，记录是否正确插入/更新/删除，数据完整性是否保持)。在适当情况下，使用 `COUNT(*)` 进行存在性检查。

3.  **预判唯一约束冲突:**
    *   **问题:** 批量更新/插入时的一个常见陷阱是尝试将唯一字段 (例如 `username`, `email`) 为多个记录设置*相同的值*。
    *   **行动 (在测试中):**
        *   如果专门测试此失败场景，确保 API 能优雅处理 (例如返回 409 错误、回滚、清晰的错误消息)。
        *   如果测试其他逻辑 (如 `WHERE` 子句)，确保为唯一字段设置的值对于每个被修改的记录本身都是唯一的 (例如，如果 API 支持，可以在 `set` 负载中使用 SQL 函数如 `CONCAT(field_value_prefix, id)`，或在测试负载中改变值)。
    *   **示例:** `test_batch_where_clause_operators` 因 `username` 及后续 `email` 的唯一约束冲突而失败，直到在 `set` 子句中使用 `CONCAT` 与 `id` 来确保唯一性才解决。

4.  **验证支持的语法/操作符:**
    *   **问题:** API 后端可能对 SQL 函数 (在 `set` 子句中) 或 `WHERE` 子句操作符有特定的白名单 (例如 `NOT LIKE` 最初在 `app.py` 中不受支持)。
    *   **行动:** 如果测试需要特定的操作符或 SQL 函数，确保它被 API 后端明确支持和处理。否则，这可能表明存在功能差距或需要更新 API 的解析/执行逻辑。

### C. 调试期间:
1.  **迭代方法与小步快跑:** 对于复杂的故障，分解问题，不要试图一次修复所有问题。
2.  **有效利用日志:**
    *   在 Flask 应用中使用 `app.logger.debug/info/error` 获取服务器端洞察。
    *   如果 `pytest -s` 未显示 Flask 应用日志 (由于 `pytest` 的捕获机制或其他配置原因)，可在 API 代码中临时切换到带有清晰、唯一前缀的 `print()` 语句，以便在测试运行时直接查看输出。*之后务必移除这些临时 `print` 语句。*
3.  **仔细分析完整的错误输出:** 密切关注:
    *   `pytest` 中失败的确切断言。
    *   API 的 HTTP 状态码和 JSON 错误响应。
    *   捕获到的服务器端日志 (Flask `app.logger` 或临时 `print` 输出)，包括任何堆栈跟踪。它们通常包含有关内部状态或未处理异常的精确线索。

### D. 测试/修复后:
1.  **移除临时调试代码:** 清理应用代码 (`app.py`) 中的所有 `print` 语句或过多/临时的日志记录。
2.  **记录经验与关键问题:** 在相关测试文件的末尾或专用文档 (如此文档) 中，以注释形式总结重要问题、其根本原因、解决方案以及任何新的理解。这对未来的自己和其他开发者非常有帮助。
3.  **更新测试计划:** 细致地更新 `TEXT_PLAN.txt` (或类似规划文档)，标记已完成项，并记录任何新发现的测试用例。

## III. 通用良好习惯 (重申自用户自定义指令与实践经验):
*   **最小化、有针对性的改动:** 应用最小有效改动来修复问题或实现功能。除非绝对必要且充分理解，否则避免进行广泛、影响面大的改动。
*   **验证，而非假设:** 尤其对于 API 行为、数据状态以及代码改动的影响。
*   **先阅读，后编码:** 在修改或编写新的测试/代码之前，理解现有代码、上下文和需求 (或在调试情况下的实际行为)。
*   **测试边缘情况和错误条件:** 不要只测试"理想路径"，确保鲁棒的错误处理和优雅的失败机制。
*   **保持一致性:** 遵循项目现有的编码风格、命名约定和架构模式。
*   **编写清晰的提交信息:** 每次代码提交都应有明确的、描述性的信息，说明本次提交的目的和主要变更内容。这有助于代码审查、版本回溯和理解项目历史。
*   **文档同步:** 当代码（尤其是 API 行为、数据结构）发生重要变更时，及时更新相关的项目文档（如 `PROJECT_STRUCTURE.md`、流程说明文档、API 文档等），确保文档与代码的一致性。
*   **形成测试与实际运行的验证闭环 (新增):** 集成测试的通过是重要的步骤，但务必通过在主应用中实际运行相同的场景来最终验证修改的正确性。主应用日志对于诊断测试 Mock 与实际行为之间的差异至关重要。

牢记以上各点，未来在此项目上的测试与开发工作，特别是针对像 `/execute_batch_operations` 这样复杂且功能强大的端点，将会更高效、可预测，并带来更健壮可靠的成果。 